#!/usr/bin/env python3
"""
Extrator de dados para Dashboard Power BI
Vers√£o h√≠brida: requests + Selenium (quando dispon√≠vel)
"""

import time
import json
import requests
from datetime import datetime
from bs4 import BeautifulSoup
from multi_source_indexer import MultiSourceIndexer

class PowerBIExtractor:
    """Extrator de dados para dashboards Power BI"""
    
    def __init__(self, dashboard_url: str):
        self.dashboard_url = dashboard_url
        self.session = requests.Session()
        
        # Headers para parecer um navegador real
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
    
    def extract_with_requests(self) -> dict:
        """Extrai dados usando requests (m√©todo b√°sico)"""
        print(f"üîç Tentando extra√ß√£o b√°sica com requests...")
        
        try:
            response = self.session.get(self.dashboard_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Remove scripts e estilos
            for script in soup(["script", "style"]):
                script.decompose()
            
            # Extrai texto vis√≠vel
            text = soup.get_text(separator=' ', strip=True)
            
            # Procura por dados espec√≠ficos
            data_elements = self._extract_basic_data(soup, response.text)
            
            return {
                'source': 'Power BI Dashboard (Basic)',
                'url': self.dashboard_url,
                'text': text,
                'type': 'dashboard',
                'collected_at': datetime.now().isoformat(),
                'data_elements': data_elements,
                'page_title': soup.title.string if soup.title else 'N/A',
                'method': 'requests',
                'status_code': response.status_code,
                'content_length': len(response.content)
            }
            
        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o b√°sica: {e}")
            return None
    
    def _extract_basic_data(self, soup: BeautifulSoup, raw_html: str) -> dict:
        """Extrai dados b√°sicos do HTML"""
        data = {
            'titles': [],
            'scripts': [],
            'meta_info': [],
            'embedded_data': []
        }
        
        # Procura por t√≠tulos
        for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            titles = soup.find_all(tag)
            for title in titles:
                text = title.get_text(strip=True)
                if text and len(text) > 2:
                    data['titles'].append(text)
        
        # Procura por meta informa√ß√µes
        meta_tags = soup.find_all('meta')
        for meta in meta_tags:
            if meta.get('name') or meta.get('property'):
                data['meta_info'].append({
                    'name': meta.get('name') or meta.get('property'),
                    'content': meta.get('content', '')
                })
        
        # Procura por dados embarcados em scripts
        import re
        
        # Procura por configura√ß√µes do Power BI
        powerbi_patterns = [
            r'powerbi[^"]*',
            r'dashboard[^"]*',
            r'report[^"]*',
            r'visual[^"]*'
        ]
        
        for pattern in powerbi_patterns:
            matches = re.findall(pattern, raw_html, re.IGNORECASE)
            data['embedded_data'].extend(matches[:10])  # Primeiros 10 matches
        
        # Procura por URLs de API
        api_patterns = [
            r'https://[^"]*api[^"]*',
            r'https://[^"]*powerbi[^"]*'
        ]
        
        for pattern in api_patterns:
            matches = re.findall(pattern, raw_html)
            data['embedded_data'].extend(matches[:5])  # Primeiros 5 matches
        
        return data
    
    def extract_with_selenium(self) -> dict:
        """Extrai dados usando Selenium (m√©todo avan√ßado)"""
        print(f"üîç Tentando extra√ß√£o avan√ßada com Selenium...")
        
        try:
            # Tenta importar Selenium
            from selenium import webdriver
            from selenium.webdriver.edge.service import Service as EdgeService
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            
            # Configura op√ß√µes do Edge
            options = webdriver.EdgeOptions()
            options.add_argument('--headless')  # Executa em background
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            
            # Tenta usar driver local se existir
            driver_path = "msedgedriver.exe"
            try:
                service = EdgeService(executable_path=driver_path)
                driver = webdriver.Edge(service=service, options=options)
            except:
                print("‚ùå Driver local n√£o encontrado, tentando webdriver-manager...")
                from webdriver_manager.microsoft import EdgeChromiumDriverManager
                service = EdgeService(EdgeChromiumDriverManager().install())
                driver = webdriver.Edge(service=service, options=options)
            
            try:
                # Acessa o dashboard
                driver.get(self.dashboard_url)
                
                # Aguarda carregamento
                time.sleep(15)
                
                # Extrai conte√∫do
                page_source = driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                
                # Remove scripts e estilos
                for script in soup(["script", "style"]):
                    script.decompose()
                
                text = soup.get_text(separator=' ', strip=True)
                data_elements = self._extract_advanced_data(soup, driver)
                
                # Tira screenshot
                screenshot_path = f"powerbi_screenshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                driver.save_screenshot(screenshot_path)
                
                return {
                    'source': 'Power BI Dashboard (Advanced)',
                    'url': self.dashboard_url,
                    'text': text,
                    'type': 'dashboard',
                    'collected_at': datetime.now().isoformat(),
                    'data_elements': data_elements,
                    'page_title': driver.title,
                    'method': 'selenium',
                    'screenshot': screenshot_path
                }
                
            finally:
                driver.quit()
                
        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o avan√ßada: {e}")
            return None
    
    def _extract_advanced_data(self, soup: BeautifulSoup, driver) -> dict:
        """Extrai dados avan√ßados usando Selenium"""
        data = {
            'titles': [],
            'interactive_elements': [],
            'visual_containers': [],
            'data_values': []
        }
        
        try:
            # Procura por elementos interativos
            interactive_selectors = [
                "[data-testid]",
                "[role='button']",
                "[role='tab']",
                ".visual-container",
                ".powerbi-visual"
            ]
            
            for selector in interactive_selectors:
                try:
                    elements = driver.find_elements("css selector", selector)
                    for elem in elements[:10]:  # Primeiros 10
                        text = elem.text.strip()
                        if text and len(text) > 1:
                            data['interactive_elements'].append(text)
                except:
                    continue
            
            # Procura por t√≠tulos
            for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                titles = soup.find_all(tag)
                for title in titles:
                    text = title.get_text(strip=True)
                    if text and len(text) > 2:
                        data['titles'].append(text)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao extrair dados avan√ßados: {e}")
        
        return data
    
    def extract_data(self) -> dict:
        """M√©todo principal de extra√ß√£o"""
        print(f"üöÄ INICIANDO EXTRA√á√ÉO DO DASHBOARD POWER BI")
        print(f"URL: {self.dashboard_url}")
        print("=" * 60)
        
        # Tenta primeiro com requests
        data = self.extract_with_requests()
        
        if data and len(data['text']) > 100:
            print(f"‚úÖ Extra√ß√£o b√°sica bem-sucedida!")
            return data
        
        # Se requests n√£o funcionou bem, tenta Selenium
        print(f"üîÑ Tentando m√©todo avan√ßado...")
        selenium_data = self.extract_with_selenium()
        
        if selenium_data:
            print(f"‚úÖ Extra√ß√£o avan√ßada bem-sucedida!")
            return selenium_data
        
        # Se nenhum m√©todo funcionou, retorna o que conseguiu
        if data:
            print(f"‚ö†Ô∏è  Retornando dados b√°sicos dispon√≠veis")
            return data
        
        print(f"‚ùå Falha em todos os m√©todos de extra√ß√£o")
        return None
    
    def save_to_file(self, data: dict, filename: str = None):
        """Salva os dados extra√≠dos em arquivo"""
        if not filename:
            filename = f"powerbi_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Dados salvos em: {filename}")
        return filename

def main():
    """Fun√ß√£o principal"""
    # URL do dashboard fornecida pelo usu√°rio
    dashboard_url = "https://app.powerbi.com/view?r=eyJrIjoiZGEyMzBkMWYtNzNiMS00ZmIyLTg5YzgtZDk5ZWE5ODU4ZDg2IiwidCI6IjJiMjY2ZmE5LTNmOTMtNGJiMS05ODMwLTYzNDY3NTJmMDNlNCIsImMiOjF9"
    
    # Cria o extrator
    extractor = PowerBIExtractor(dashboard_url)
    
    # Extrai os dados
    data = extractor.extract_data()
    
    if data:
        print(f"\nüìä DADOS EXTRA√çDOS:")
        print(f"   M√©todo: {data.get('method', 'N/A')}")
        print(f"   T√≠tulo da p√°gina: {data.get('page_title', 'N/A')}")
        print(f"   Tamanho do texto: {len(data['text']):,} caracteres")
        print(f"   Elementos encontrados: {len(data['data_elements'])}")
        
        if 'status_code' in data:
            print(f"   Status HTTP: {data['status_code']}")
        if 'content_length' in data:
            print(f"   Tamanho do conte√∫do: {data['content_length']:,} bytes")
        
        # Salva os dados
        filename = extractor.save_to_file(data)
        
        # Tenta indexar no sistema
        print(f"\nüîÑ INDEXANDO NO SISTEMA...")
        try:
            indexer = MultiSourceIndexer()
            
            # Prepara o documento para indexa√ß√£o
            custom_docs = [{
                'text': data['text'],
                'url': data['url'],
                'type': data['type']
            }]
            
            indexer.add_custom_source("Power BI Dashboard", custom_docs)
            print(f"‚úÖ Dashboard indexado com sucesso!")
            
        except Exception as e:
            print(f"‚ùå Erro ao indexar: {e}")
            print(f"üí° Dados salvos em {filename} para indexa√ß√£o manual")
        
        print(f"\nüéâ EXTRA√á√ÉO CONCLU√çDA!")
        print(f"üìÅ Arquivo de dados: {filename}")
        
        # Mostra preview dos dados
        print(f"\nüìã PREVIEW DOS DADOS:")
        print(f"   Primeiros 200 caracteres do texto:")
        print(f"   {data['text'][:200]}...")
        
    else:
        print(f"‚ùå Falha na extra√ß√£o dos dados")

if __name__ == "__main__":
    main()