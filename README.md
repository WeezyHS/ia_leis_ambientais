# Scraper de Normas Ambientais ABNT

Este projeto implementa um scraper automatizado para extrair informaÃ§Ãµes sobre normas ambientais do catÃ¡logo da ABNT (AssociaÃ§Ã£o Brasileira de Normas TÃ©cnicas).

## ğŸ¯ Objetivo

Automatizar a coleta de informaÃ§Ãµes sobre normas tÃ©cnicas relacionadas ao meio ambiente, sustentabilidade e gestÃ£o ambiental disponÃ­veis no catÃ¡logo oficial da ABNT.

## ğŸ“‹ Funcionalidades

- âœ… Busca automatizada por termos ambientais
- âœ… ExtraÃ§Ã£o de cÃ³digos de normas (NBR, ISO)
- âœ… Coleta de tÃ­tulos e descriÃ§Ãµes
- âœ… IdentificaÃ§Ã£o de preÃ§os
- âœ… Tratamento automÃ¡tico de CAPTCHA
- âœ… GeraÃ§Ã£o de relatÃ³rios consolidados
- âœ… Suporte a mÃºltiplos termos de busca

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **Selenium WebDriver** - AutomaÃ§Ã£o do navegador
- **Chrome/Chromium** - Navegador para scraping
- **JSON** - Armazenamento de dados
- **Regex** - Processamento de texto

## ğŸ“¦ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <url-do-repositorio>
cd ia_leis_ambientais
```

2. **Crie um ambiente virtual:**
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# ou
source venv/bin/activate  # Linux/Mac
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Instale o ChromeDriver:**
   - Baixe o ChromeDriver compatÃ­vel com sua versÃ£o do Chrome
   - Adicione ao PATH do sistema ou coloque na pasta do projeto

## ğŸš€ Como Usar

### Uso BÃ¡sico

```python
from abnt_scraper_final import ABNTScraper

# Inicializa o scraper
scraper = ABNTScraper()

# Realiza busca por um termo
results = scraper.search_and_extract("ambiental")

# Fecha o scraper
scraper.close()
```

### ExecuÃ§Ã£o do Script Principal

```bash
python abnt_scraper_final.py
```

Este script irÃ¡:
1. Buscar por 7 termos ambientais predefinidos
2. Extrair informaÃ§Ãµes de cada resultado
3. Gerar arquivos HTML e JSON para cada busca
4. Criar um relatÃ³rio consolidado

### DemonstraÃ§Ãµes Interativas

```bash
python demo_scraper.py
```

Oferece 4 opÃ§Ãµes de demonstraÃ§Ã£o:
1. Busca simples por 'ambiental'
2. Busca mÃºltipla (Ã¡gua, resÃ­duos, ar)
3. AnÃ¡lise especÃ­fica ISO 14000
4. Executar todas as demonstraÃ§Ãµes

## ğŸ“Š Resultados

### Ãšltimos Resultados Obtidos

- **7 termos pesquisados**: ambiental, environmental, sustentabilidade, resÃ­duos, Ã¡gua, ar, solo
- **1.702 produtos encontrados** no total
- **21 normas Ãºnicas identificadas**

### DistribuiÃ§Ã£o por Termo:
- **Ã¡gua**: 1.126 produtos
- **solo**: 295 produtos
- **ambiental**: 120 produtos
- **resÃ­duos**: 112 produtos
- **sustentabilidade**: 49 produtos
- **environmental**: 0 produtos
- **ar**: 0 produtos

### Principais Normas Identificadas:
1. **ABNT NBR ISO 14040:2025** - Environmental management - Life cycle assessment
2. **ABNT NBR ISO 14030-3:2025** - Environmental performance evaluation
3. **ABNT PR 2030-1:2024** - Environmental, social and governance (ESG)
4. **ABNT NBR ISO 14001:2015** - Environmental management systems
5. **ABNT NBR 9895:2025** - Environmental passive in soil and groundwater

## ğŸ“ Estrutura de Arquivos

```
ia_leis_ambientais/
â”œâ”€â”€ abnt_scraper_final.py          # Script principal do scraper
â”œâ”€â”€ demo_scraper.py                # DemonstraÃ§Ãµes interativas
â”œâ”€â”€ generate_report.py             # Gerador de relatÃ³rios
â”œâ”€â”€ requirements.txt               # DependÃªncias do projeto
â”œâ”€â”€ README.md                      # DocumentaÃ§Ã£o
â”œâ”€â”€ abnt_consolidated_results.json # Resultados consolidados
â”œâ”€â”€ abnt_report.json              # RelatÃ³rio detalhado
â”œâ”€â”€ abnt_report.txt               # RelatÃ³rio legÃ­vel
â””â”€â”€ resultados/                   # Arquivos de resultados individuais
    â”œâ”€â”€ abnt_results_ambiental.html
    â”œâ”€â”€ abnt_results_ambiental.json
    â””â”€â”€ ...
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### ParÃ¢metros do Scraper

```python
scraper = ABNTScraper(
    headless=True,          # ExecuÃ§Ã£o sem interface grÃ¡fica
    max_wait_time=30,       # Tempo mÃ¡ximo de espera (segundos)
    enable_captcha_handling=True  # Tratamento automÃ¡tico de CAPTCHA
)
```

### Termos de Busca Personalizados

```python
termos_personalizados = [
    "gestÃ£o ambiental",
    "ISO 14001",
    "sustentabilidade",
    "carbono",
    "emissÃµes"
]

for termo in termos_personalizados:
    results = scraper.search_and_extract(termo)
```

## ğŸš¨ ConsideraÃ§Ãµes Importantes

### LimitaÃ§Ãµes
- O site da ABNT pode implementar medidas anti-bot
- CAPTCHA pode aparecer e requer intervenÃ§Ã£o manual
- Velocidade limitada para evitar sobrecarga do servidor
- Alguns resultados podem nÃ£o ser capturados devido Ã  estrutura dinÃ¢mica da pÃ¡gina

### Boas PrÃ¡ticas
- Use delays entre requisiÃ§Ãµes
- Monitore logs para identificar problemas
- Mantenha o ChromeDriver atualizado
- Respeite os termos de uso do site da ABNT

### Tratamento de Erros
- Timeout automÃ¡tico para pÃ¡ginas que nÃ£o carregam
- Retry automÃ¡tico em caso de falhas temporÃ¡rias
- Logs detalhados para debugging
- Graceful shutdown em caso de interrupÃ§Ã£o

## ğŸ“ˆ AnÃ¡lise dos Dados

### GeraÃ§Ã£o de RelatÃ³rios

```bash
python generate_report.py
```

Gera:
- `abnt_report.json`: Dados estruturados
- `abnt_report.txt`: RelatÃ³rio legÃ­vel

### AnÃ¡lise EstatÃ­stica

O relatÃ³rio inclui:
- Contagem total de produtos por termo
- Lista de normas Ãºnicas identificadas
- DistribuiÃ§Ã£o de preÃ§os (quando disponÃ­vel)
- AnÃ¡lise temporal das normas

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© destinado apenas para fins educacionais e de pesquisa. Respeite os termos de uso do site da ABNT.

## ğŸ†˜ Suporte

Para problemas ou dÃºvidas:
1. Verifique os logs de erro
2. Consulte a documentaÃ§Ã£o do Selenium
3. Abra uma issue no repositÃ³rio

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Selenium](https://selenium-python.readthedocs.io/)
- [Site oficial ABNT](https://www.abnt.org.br/)
- [CatÃ¡logo ABNT](https://www.abntcatalogo.com.br/)

---

**Desenvolvido para automatizar a coleta de informaÃ§Ãµes sobre normas ambientais brasileiras** ğŸŒ±

## ğŸŒŸ Funcionalidades Principais

### Sistema de MÃºltiplas Fontes
- **Coleta automatizada** de mÃºltiplas fontes governamentais
- **Fontes prÃ©-configuradas**: Assembleia Legislativa do Tocantins, Planalto, IBAMA
- **Interface web** para gerenciar fontes de dados
- **API REST** para adicionar novas fontes programaticamente
- **Coleta em background** para nÃ£o bloquear a interface

### Processamento Inteligente
- ExtraÃ§Ã£o estruturada de dados: tÃ­tulo, descriÃ§Ã£o e conteÃºdo completo
- Filtro semÃ¢ntico para selecionar apenas leis ambientais relevantes
- IndexaÃ§Ã£o vetorial no Pinecone para buscas por similaridade semÃ¢ntica
- GeraÃ§Ã£o de embeddings usando o modelo **text-embedding-3-small** da OpenAI
- IntegraÃ§Ã£o com GPT-4o-mini para geraÃ§Ã£o de respostas em linguagem natural
- Mecanismo para evitar duplicaÃ§Ã£o de leis no banco vetorial

### Interface e API
- **Interface web moderna** para consultas e gerenciamento
- **API desenvolvida com FastAPI** para upload, consulta e resumo das leis
- **DocumentaÃ§Ã£o automÃ¡tica** da API (Swagger/OpenAPI)
- **Suporte a mÃºltiplos formatos**: PDF, HTML, texto direto

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.11+**
- **FastAPI** - Framework web moderno e rÃ¡pido
- **Selenium** - AutomaÃ§Ã£o de navegador para scraping
- **BeautifulSoup** - Parsing de HTML
- **LangChain** - Framework para aplicaÃ§Ãµes com LLM
- **OpenAI API** - Embeddings e geraÃ§Ã£o de texto
- **Pinecone** - Banco de dados vetorial
- **Uvicorn** - Servidor ASGI
- **Requests** - Cliente HTTP para APIs

## ğŸš€ Como Usar

### 1. InstalaÃ§Ã£o
```bash
# Clone o repositÃ³rio
git clone <url-do-repositorio>
cd ia_leis_ambientais

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o
Crie um arquivo `.env` na raiz do projeto:
```env
OPENAI_API_KEY=sua_chave_openai
PINECONE_API_KEY=sua_chave_pinecone
PINECONE_ENVIRONMENT=sua_regiao_pinecone
```

### 3. Executar o Sistema
```bash
# Inicie o servidor
uvicorn app.main:app --reload

# Acesse a interface web
# http://localhost:8000
```

## ğŸŒ Gerenciar MÃºltiplas Fontes

### Interface Web
1. Acesse `http://localhost:8000`
2. Clique em "ğŸŒ Gerenciar Fontes"
3. Use as abas para:
   - Ver status das fontes
   - Adicionar documentos por URL
   - Adicionar documentos personalizados
   - Coletar dados automaticamente

### Via Scripts Python
```bash
# Coletar de todas as fontes configuradas
python multi_source_indexer.py

# Adicionar fonte personalizada
python add_custom_source.py

# Exemplo especÃ­fico do CONAMA
python example_conama_scraper.py
```

### Via API REST
```bash
# Verificar status das fontes
curl http://localhost:8000/multi-sources/status

# Adicionar documento por URL
curl -X POST "http://localhost:8000/multi-sources/add-url?url=https://exemplo.com/lei.pdf&source_name=Fonte%20Exemplo"

# Coletar de todas as fontes
curl -X POST http://localhost:8000/multi-sources/collect \
  -H "Content-Type: application/json" \
  -d "{}"
```

## ğŸ“š Fontes de Dados Suportadas

### PrÃ©-configuradas
- **Assembleia Legislativa do Tocantins** - Leis estaduais
- **Planalto** - Leis federais
- **IBAMA** - Normas ambientais federais

### Como Adicionar Novas Fontes
1. **Via Interface Web**: Use a aba "Adicionar Personalizado"
2. **Via Script**: Execute `add_custom_source.py`
3. **Programaticamente**: Crie um novo scraper baseado em `BaseScraper`

### Formatos Suportados
- **PDF** - ExtraÃ§Ã£o automÃ¡tica de texto
- **HTML** - Parsing com BeautifulSoup
- **Texto direto** - InserÃ§Ã£o manual

## ğŸ”§ Estrutura do Projeto

```
ia_leis_ambientais/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # AplicaÃ§Ã£o FastAPI principal
â”‚   â”œâ”€â”€ routes/                 # Rotas da API
â”‚   â”‚   â”œâ”€â”€ multi_sources.py    # Gerenciamento de mÃºltiplas fontes
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ services/               # ServiÃ§os de negÃ³cio
â”‚       â”œâ”€â”€ multi_source_scraper.py  # Sistema de scraping modular
â”‚       â””â”€â”€ ...
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html             # Interface principal
â”‚   â””â”€â”€ multi_sources.html     # Interface de gerenciamento
â”œâ”€â”€ multi_source_indexer.py    # Indexador para mÃºltiplas fontes
â”œâ”€â”€ add_custom_source.py       # Script para adicionar fontes
â”œâ”€â”€ example_conama_scraper.py  # Exemplo de scraper especÃ­fico
â”œâ”€â”€ MULTI_SOURCES_GUIDE.md     # Guia detalhado do sistema
â””â”€â”€ requirements.txt           # DependÃªncias
```
